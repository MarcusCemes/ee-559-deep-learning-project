{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-isnUSZjAx7M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AdamW, get_scheduler\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import  f1_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmqcGrIIAx7O"
      },
      "source": [
        "##### Import the multilabel data\n",
        "##### [UCBerkeley - Hate Speech Dataset (Multilabel)](https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the data locally\n",
        "#https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Columns: (135556, 131)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "## Read the measuring-hate-speech.parquet\n",
        "raw_datasets = pd.read_parquet('measuring-hate-speech.parquet')\n",
        "\n",
        "print(f\"Number of Columns: {raw_datasets.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['comment_id', 'annotator_id', 'platform', 'sentiment', 'respect',\n",
              "       'insult', 'humiliate', 'status', 'dehumanize', 'violence',\n",
              "       ...\n",
              "       'annotator_religion_hindu', 'annotator_religion_jewish',\n",
              "       'annotator_religion_mormon', 'annotator_religion_muslim',\n",
              "       'annotator_religion_nothing', 'annotator_religion_other',\n",
              "       'annotator_sexuality_bisexual', 'annotator_sexuality_gay',\n",
              "       'annotator_sexuality_straight', 'annotator_sexuality_other'],\n",
              "      dtype='object', length=131)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>race</th>\n",
              "      <th>religion</th>\n",
              "      <th>origin</th>\n",
              "      <th>gender</th>\n",
              "      <th>sexuality</th>\n",
              "      <th>age</th>\n",
              "      <th>disability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The trans women reading this tweet right now i...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: These 4 broads who criticize America...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It is about time for all illegals to go back t...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For starters bend over the one in pink and kic...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   race  religion  origin  \\\n",
              "0  Yes indeed. She sort of reminds me of the elde...   True     False   False   \n",
              "1  The trans women reading this tweet right now i...  False     False   False   \n",
              "2  Question: These 4 broads who criticize America...  False     False    True   \n",
              "3  It is about time for all illegals to go back t...  False     False    True   \n",
              "4  For starters bend over the one in pink and kic...  False     False   False   \n",
              "\n",
              "   gender  sexuality    age  disability  \n",
              "0   False      False  False       False  \n",
              "1    True      False  False       False  \n",
              "2   False      False  False       False  \n",
              "3   False      False  False       False  \n",
              "4    True      False  False       False  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# keep only text and specific targets\n",
        "raw_columns = raw_datasets.columns\n",
        "keep_columns = ['text', 'target_race', 'target_religion', 'target_origin', 'target_gender', 'target_sexuality', 'target_age', 'target_disability']\n",
        "drop_columns = [col for col in raw_columns if col not in keep_columns]\n",
        "\n",
        "raw_datasets = raw_datasets.drop(columns=drop_columns)\n",
        "\n",
        "column_mapping = {column:column.split('_')[1] for column in keep_columns if column.startswith('target')}\n",
        "raw_datasets = raw_datasets.rename(columns=column_mapping)\n",
        "raw_datasets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID2LABEL:\n",
            "{0: 'race', 1: 'religion', 2: 'origin', 3: 'gender', 4: 'sexuality', 5: 'age', 6: 'disability'}\n",
            "\n",
            "LABEL2ID:\n",
            "{'race': 0, 'religion': 1, 'origin': 2, 'gender': 3, 'sexuality': 4, 'age': 5, 'disability': 6}\n"
          ]
        }
      ],
      "source": [
        "# Get two-way label and label ID\n",
        "ID2LABEL = {idx: column for idx, column in enumerate(raw_datasets.columns[1:])}\n",
        "LABEL2ID = {column: idx for idx, column in enumerate(raw_datasets.columns[1:])}\n",
        "\n",
        "print(f\"ID2LABEL:\\n{ID2LABEL}\\n\")\n",
        "print(f\"LABEL2ID:\\n{LABEL2ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>race</th>\n",
              "      <th>religion</th>\n",
              "      <th>origin</th>\n",
              "      <th>gender</th>\n",
              "      <th>sexuality</th>\n",
              "      <th>age</th>\n",
              "      <th>disability</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The trans women reading this tweet right now i...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: These 4 broads who criticize America...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It is about time for all illegals to go back t...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For starters bend over the one in pink and kic...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   race  religion  origin  \\\n",
              "0  Yes indeed. She sort of reminds me of the elde...   True     False   False   \n",
              "1  The trans women reading this tweet right now i...  False     False   False   \n",
              "2  Question: These 4 broads who criticize America...  False     False    True   \n",
              "3  It is about time for all illegals to go back t...  False     False    True   \n",
              "4  For starters bend over the one in pink and kic...  False     False   False   \n",
              "\n",
              "   gender  sexuality    age  disability                               labels  \n",
              "0   False      False  False       False  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "1    True      False  False       False  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
              "2   False      False  False       False  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "3   False      False  False       False  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "4    True      False  False       False  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to create labels\n",
        "def create_labels(row):\n",
        "    return [float(row[label]) for label in LABEL2ID]\n",
        "\n",
        "raw_datasets['labels'] = raw_datasets.apply(create_labels, axis=1)\n",
        "raw_datasets.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_FEkRzAx7O"
      },
      "source": [
        "### Preprocessing text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An20B7vYAx7O",
        "outputId": "5fad12f8-5cf8-4806-e6e5-f2fccb921b32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "## Preprocess the TEXT data\n",
        "## Remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: remove_html_tags(x))\n",
        "\n",
        "## Remove URL\n",
        "def remove_url(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "## Lowercase\n",
        "raw_datasets['text'] = raw_datasets['text'].str.lower()\n",
        "\n",
        "## Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "## Handling Contractions using libraries\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "## Remove stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "## Lemmatization\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "raw_datasets['text'] = raw_datasets['text'].apply(lambda x: lemmatize_words(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fFnGp-_Ax7P"
      },
      "source": [
        "#### Dataset/Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9Fik-IuMl2Gd"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2tNG2TgMST05"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset: (108444, 9)\n",
            "Validation Dataset: (20334, 9)\n",
            "Test Dataset: (6778, 9)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# train (80%), validation (10%), test (10%) split\n",
        "\n",
        "train_data, temp_data = train_test_split(raw_datasets, test_size=0.2, random_state=SEED)\n",
        "validation_data, test_data = train_test_split(temp_data, test_size=0.25, random_state=SEED)\n",
        "\n",
        "print(f\"Train Dataset: {train_data.shape}\")\n",
        "print(f\"Validation Dataset: {validation_data.shape}\")\n",
        "print(f\"Test Dataset: {test_data.shape}\")\n",
        "\n",
        "# Reset the index of the DataFrames\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "# Keep only the text and labels columns \n",
        "train_data = train_data[['text', 'labels']]\n",
        "validation_data = validation_data[['text', 'labels']]\n",
        "test_data = test_data[['text', 'labels']]\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "validation_dataset = Dataset.from_pandas(validation_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n",
        "\n",
        "# Create a DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': validation_dataset,\n",
        "    'test': test_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 108444\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 20334\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 6778\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tokenize the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8dNmnpeaRNEJ"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff07e55f91eb4e4fae108d383abb1c0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/108444 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d82caa77ef14f16beb1ad234d2982b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20334 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41e35eb5afe244619e54f44677a41a0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6778 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "CHECKPOINT = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "# Define the tokenization function\n",
        "def tokenize_function(batch):\n",
        "    return tokenizer(batch['text'], truncation=True, padding='max_length')\n",
        "\n",
        "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True, remove_columns=['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 108444\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 20334\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['labels', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 6778\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_datasets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "dataloaders = {}\n",
        "for dataset_type in tokenized_datasets.keys():\n",
        "    dataloaders[dataset_type] = DataLoader(\n",
        "        dataset=tokenized_datasets[dataset_type],\n",
        "        batch_size=64,\n",
        "        shuffle=(dataset_type == 'train'), \n",
        "        collate_fn=data_collator,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CHECKPOINT,\n",
        "    problem_type='multi_label_classification',\n",
        "    num_labels=len(LABEL2ID),\n",
        "    label2id=LABEL2ID,\n",
        "    id2label=ID2LABEL,\n",
        ")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZnNREnNqdmC"
      },
      "source": [
        "#### Setup Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2vjORRaqfMf",
        "outputId": "817c402a-b881-4cd5-ecca-9829ccc6648b"
      },
      "outputs": [],
      "source": [
        "scheduler_name = 'linear'\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0, no_deprecation_warning=True)\n",
        "num_training_steps = EPOCHS * len(dataloaders['train'])\n",
        "num_warmup_steps = 0\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=scheduler_name,\n",
        "    optimizer=optimizer,\n",
        "    num_training_steps=num_training_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Accuracy Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    return np.sum(y_true==y_pred) / y_true.size\n",
        "\n",
        "def compute_metrics(preds):\n",
        "    logits, labels = preds\n",
        "    preds_= torch.nn.functional.sigmoid(torch.Tensor(logits))\n",
        "    preds_ = (preds_ >= 0.50).int().numpy()\n",
        "    samples_acc = accuracy_score(labels, preds_)\n",
        "    samples_f1 = f1_score(labels, preds_, average='samples', zero_division=0)\n",
        "    return {\n",
        "        'accuracy': samples_acc,\n",
        "        'f1': samples_f1,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvLOZaOYq0mI"
      },
      "source": [
        "#### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO3pp7Xq3cj",
        "outputId": "2912b97c-ec76-47ca-b4f6-1176390df3e4"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader):\n",
        "\n",
        "    loss = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "    \n",
        "    # set to train mode\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch.to(device)\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        predictions = torch.nn.functional.sigmoid(outputs.logits).cpu()\n",
        "        predictions = (predictions >= 0.50).int().numpy()\n",
        "        labels = batch['labels']\n",
        "        \n",
        "        outputs.loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        \n",
        "        loss += outputs.loss.item()\n",
        "        train_preds += predictions.tolist()\n",
        "        train_labels += labels.tolist()\n",
        "        \n",
        "    loss /= len(dataloader)\n",
        "    samples_acc = accuracy_score(np.array(train_labels), np.array(train_preds))\n",
        "    samples_f1 = f1_score(np.array(train_labels), np.array(train_preds), average='samples', zero_division=0)\n",
        "    return {\n",
        "        'loss': loss,\n",
        "        'accuracy': samples_acc,\n",
        "        'f1': samples_f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVFsvSa8sCg1"
      },
      "source": [
        "#### Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7wnDBL3Sr_Zk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "\n",
        "    loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in tqdm(dataloader):\n",
        "\n",
        "            batch.to(device)\n",
        "            outputs = model(**batch)\n",
        "            \n",
        "            predictions = torch.nn.functional.sigmoid(outputs.logits).cpu()\n",
        "            predictions = (predictions >= 0.50).cpu().numpy()\n",
        "            labels = batch['labels']\n",
        "            \n",
        "            loss += outputs.loss.item()\n",
        "            val_preds += predictions.tolist()\n",
        "            val_labels += labels.tolist()\n",
        "            \n",
        "    # evaluation metrics\n",
        "    loss /= len(dataloader)\n",
        "    samples_acc = accuracy_score(np.array(val_labels), np.array(val_preds))\n",
        "    samples_f1 = f1_score(np.array(val_labels), np.array(val_preds), average='samples', zero_division=0)\n",
        "    return {\n",
        "        'loss': loss,\n",
        "        'accuracy': samples_acc,\n",
        "        'f1': samples_f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    train_metrics = train(model, dataloaders['train'])\n",
        "    validation_metrics = evaluate(model, dataloaders['validation'])\n",
        "          \n",
        "    print(f\"Epoch {epoch+1}\", end=\" | \")\n",
        "    print(f\"Train loss: {train_metrics['loss']:.5f}\", end=\" | \")\n",
        "    print(f\"Validation loss: {validation_metrics['loss']:.5f}\", end=\" | \")\n",
        "    print(f\"Validation accuracy: {validation_metrics['accuracy']:.5f}\", end=\" | \")\n",
        "    print(f\"Validation F1: {validation_metrics['f1']:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMa-pFT4eLAy"
      },
      "outputs": [],
      "source": [
        "#Import\n",
        "#! pip install lime\n",
        "#! pip install transformers-interpret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwGhn9reeNZC"
      },
      "outputs": [],
      "source": [
        "#samples = [17, 4, 44, 3, 8, 27, 71, 74]\n",
        "#attributions = dict()\n",
        "#attributions['LIME'] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLziYQw3eWuD"
      },
      "outputs": [],
      "source": [
        "#import lime\n",
        "#from lime.lime_text import LimeTextExplainer\n",
        "#explainer = LimeTextExplainer(class_names=columns_to_transform, split_expression='\\s+', bow=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePv2Rh1F6V1I"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "def predictor(texts):\n",
        "\n",
        "    encodings = tokenizer(texts,\n",
        "                           padding='max_length',\n",
        "                           truncation=True,\n",
        "                           max_length=MAX_LEN,\n",
        "                           return_tensors='pt')\n",
        "\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "    token_type_ids = encodings['token_type_ids'].to(device)\n",
        "\n",
        "    logits = multilabel_model(input_ids, attention_mask, token_type_ids)\n",
        "    probabilities = F.softmax(logits, dim=1)\n",
        "\n",
        "    return probabilities.cpu().detach().numpy()\n",
        "\n",
        "for idx in samples:\n",
        "    instance = val_texts.iloc[idx].text\n",
        "\n",
        "    # Call predictor with the current instance\n",
        "    exp = explainer.explain_instance(instance, predictor, num_features=200, num_samples=64)\n",
        "\n",
        "    explanation_dict = dict(list(exp.as_map().values())[0])\n",
        "    tokens = val_texts.iloc[idx].text.split(' ')\n",
        "    scores = []\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "        scores.append((tokens[i], explanation_dict[i]))\n",
        "\n",
        "    attributions['LIME'].append(scores)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjtOrEylewau"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm, transforms\n",
        "\n",
        "# Plotting Code from innvestigate library: https://github.com/albermax/innvestigate\n",
        "def plot_text_heatmap(words, scores, title=\"\", width=10, height=0.2, verbose=0, max_word_per_line=20):\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    ax.set_title(title, loc='left')\n",
        "    tokens = words\n",
        "    if verbose > 0:\n",
        "        print('len words : %d | len scores : %d' % (len(words), len(scores)))\n",
        "\n",
        "    cmap = plt.cm.ScalarMappable(cmap=cm.bwr)\n",
        "    cmap.set_clim(0, 1)\n",
        "\n",
        "    canvas = ax.figure.canvas\n",
        "    t = ax.transData\n",
        "\n",
        "    # normalize scores to the followings:\n",
        "    # - negative scores in [0, 0.5]\n",
        "    # - positive scores in (0.5, 1]\n",
        "    normalized_scores = 0.5 * scores / np.max(np.abs(scores)) + 0.5\n",
        "\n",
        "    if verbose > 1:\n",
        "        print('Raw score')\n",
        "        print(scores)\n",
        "        print('Normalized score')\n",
        "        print(normalized_scores)\n",
        "\n",
        "    # make sure the heatmap doesn't overlap with the title\n",
        "    loc_y = -0.2\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        *rgb, _ = cmap.to_rgba(normalized_scores[i], bytes=True)\n",
        "        color = '#%02x%02x%02x' % tuple(rgb)\n",
        "\n",
        "        text = ax.text(0.0, loc_y, token,\n",
        "                       bbox={\n",
        "                           'facecolor': color,\n",
        "                           'pad': 5.0,\n",
        "                           'linewidth': 1,\n",
        "                           'boxstyle': 'round,pad=0.5'\n",
        "                       }, transform=t)\n",
        "\n",
        "        text.draw(canvas.get_renderer())\n",
        "        ex = text.get_window_extent()\n",
        "\n",
        "        # create a new line if the line exceeds the length\n",
        "        if (i+1) % max_word_per_line == 0:\n",
        "            loc_y = loc_y -  2.5\n",
        "            t = ax.transData\n",
        "        else:\n",
        "            t = transforms.offset_copy(text._transform, x=ex.width+15, units='dots')\n",
        "\n",
        "    if verbose == 0:\n",
        "        ax.axis('off')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVJMgkbFezl9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Plotting\n",
        "methods = ['LIME']\n",
        "\n",
        "for sample_id in range(len(samples)):\n",
        "    for method in methods:\n",
        "        analysis = attributions[method][sample_id]\n",
        "        words = [t[0] for t in analysis]\n",
        "        scores = np.array([t[1] for t in analysis])\n",
        "        plot_text_heatmap(words, scores, title='Method: %s' % method, verbose=0)\n",
        "    plt.show()\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
