{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7-Kh8MyAx7K"
      },
      "source": [
        "##### APPROACH:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEhqlD05Ax7L"
      },
      "source": [
        "Further fine-tuning an already fine-tuned model(HATE-SPEECH-BERT) for multilabel classification to identify subcategories of hate speech requires us to assess whether there are improvements in accuracy, precision, recall (F1 score) by initially using a triple classification model for hate speech detection before fine-tuning for multilabel classification. Alternatively, it may be worthwhile to directly fine-tune the model(BERT-LARGE) for multilabel classification from the start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X09Wc4F4Ax7M"
      },
      "source": [
        "#### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install contractions\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ],
      "metadata": {
        "id": "1m9dEbdIz0H-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32868a34-cfa0-42c4-c80b-c69d4b977f7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 880, in try_parse\n",
            "    return self._parse(instring, loc, doActions=False)[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 821, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 2987, in parseImpl\n",
            "    raise ParseException(instring, loc, self.errmsg, self)\n",
            "pip._vendor.pyparsing.exceptions.ParseException: Expected Re:(\"\\n        (?P<operator>(~=|==|!=|<=|>=|<|>|===))\\n        (?P<version>\\n            (?:\\n                # The identity operators allow for an escape hatch that will\\n                # do an exact string match of the version you wish to install.\\n                # This will not be parsed by PEP 440 and we cannot determine\\n                # any semantic meaning from it. This operator is discouraged\\n                # but included entirely as an escape hatch.\\n                (?<====)  # Only match for the identity operator\\n                \\s*\\n                [^\\s]*    # We just match everything, except for whitespace\\n                          # since we are only testing for strict identity.\\n            )\\n            |\\n            (?:\\n                # The (non)equality operators allow for wild card and local\\n                # versions to be specified so we have to define these two\\n                # operators separately to enable that.\\n                (?<===|!=)            # Only match for equals and not equals\\n\\n                \\s*\\n                v?\\n                (?:[0-9]+!)?          # epoch\\n                [0-9]+(?:\\.[0-9]+)*   # release\\n                (?:                   # pre release\\n                    [-_\\.]?\\n                    (a|b|c|rc|alpha|beta|pre|preview)\\n                    [-_\\.]?\\n                    [0-9]*\\n                )?\\n                (?:                   # post release\\n                    (?:-[0-9]+)|(?:[-_\\.]?(post|rev|r)[-_\\.]?[0-9]*)\\n                )?\\n\\n                # You cannot use a wild card and a dev or local version\\n                # together so group them with a | and make them optional.\\n                (?:\\n                    (?:[-_\\.]?dev[-_\\.]?[0-9]*)?         # dev release\\n                    (?:\\+[a-z0-9]+(?:[-_\\.][a-z0-9]+)*)? # local\\n                    |\\n                    \\.\\*  # Wild card syntax of .*\\n                )?\\n            )\\n            |\\n            (?:\\n                # The compatible operator requires at least two digits in the\\n                # release segment.\\n                (?<=~=)               # Only match for the compatible operator\\n\\n                \\s*\\n                v?\\n                (?:[0-9]+!)?          # epoch\\n                [0-9]+(?:\\.[0-9]+)+   # release  (We have a + instead of a *)\\n                (?:                   # pre release\\n                    [-_\\.]?\\n                    (a|b|c|rc|alpha|beta|pre|preview)\\n                    [-_\\.]?\\n                    [0-9]*\\n                )?\\n                (?:                                   # post release\\n                    (?:-[0-9]+)|(?:[-_\\.]?(post|rev|r)[-_\\.]?[0-9]*)\\n                )?\\n                (?:[-_\\.]?dev[-_\\.]?[0-9]*)?          # dev release\\n            )\\n            |\\n            (?:\\n                # All other operators only allow a sub set of what the\\n                # (non)equality operators do. Specifically they do not allow\\n                # local versions to be specified nor do they allow the prefix\\n                # matching wild cards.\\n                (?<!==|!=|~=)         # We have special cases for these\\n                                      # operators so we want to make sure they\\n                                      # don't match here.\\n\\n                \\s*\\n                v?\\n                (?:[0-9]+!)?          # epoch\\n                [0-9]+(?:\\.[0-9]+)*   # release\\n                (?:                   # pre release\\n                    [-_\\.]?\\n                    (a|b|c|rc|alpha|beta|pre|preview)\\n                    [-_\\.]?\\n                    [0-9]*\\n                )?\\n                (?:                                   # post release\\n                    (?:-[0-9]+)|(?:[-_\\.]?(post|rev|r)[-_\\.]?[0-9]*)\\n                )?\\n                (?:[-_\\.]?dev[-_\\.]?[0-9]*)?          # dev release\\n            )\\n        )\\n        \"), found ';'  (at char 9), (line:1, col:10)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3958, in parseImpl\n",
            "    loc2 = e.try_parse(instring, loc, raise_fatal=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 880, in try_parse\n",
            "    return self._parse(instring, loc, doActions=False)[0]\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 964, in handle\n",
            "    rv = self.filter(record)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moIcniO5pDXx",
        "outputId": "f0c7a509-de64-4ffa-a21d-0e67c562d08a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-isnUSZjAx7M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr3CQQcfAx7N"
      },
      "source": [
        "#### Loading the pretrained_model\n",
        "##### [hateBert](https://huggingface.co/GroNLP/hateBERT) Already fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NNR16o2Ax7N",
        "outputId": "1e146ebc-0188-4e56-93e5-4f91a0a7b210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hateBERT' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "## get the model from the huggingface model hub\n",
        "!git clone https://huggingface.co/GroNLP/hateBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAkN8RWmAx7N",
        "outputId": "b79ccd87-d335-4f88-d415-9b689f443ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "## If you download the model locally , you can load it from the local path\n",
        "PATH = os.getcwd()+\"/hateBERT\"\n",
        "\n",
        "## Load the BERT model\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained(PATH)\n",
        "model = BertModel.from_pretrained(PATH)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aITbcSdMAx7N",
        "outputId": "048f9536-253a-4b0c-a30c-36677a1bc114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 7592, 2088,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.6163,  0.4899,  0.6045,  ..., -0.0070,  0.6881,  0.5794],\n",
            "         [-0.7543, -0.0851,  0.9398,  ..., -0.3023, -0.1036,  0.7563],\n",
            "         [-0.4167,  0.3670,  0.5797,  ..., -0.2335,  0.2327, -0.3771],\n",
            "         [ 0.1706,  0.1823,  1.2238,  ...,  0.1885,  1.3003,  0.2482]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8061, -0.1458,  0.9448,  0.6965, -0.7556, -0.2725,  0.7985,  0.1897,\n",
            "          0.8852, -0.9938,  0.4638, -0.3088,  0.9876, -0.8221,  0.9338, -0.0994,\n",
            "         -0.0384, -0.3089,  0.4715, -0.3408,  0.7167, -0.6686,  0.7346, -0.0056,\n",
            "          0.0972, -0.5668, -0.4905,  0.9583,  0.9329,  0.7648, -0.6556,  0.1152,\n",
            "         -0.9940, -0.3204,  0.8402, -0.9773, -0.0690, -0.6670, -0.0889, -0.0813,\n",
            "         -0.9264,  0.3244,  0.9340,  0.2341,  0.0877, -0.1269, -0.9188,  0.3369,\n",
            "         -0.8906, -0.9399, -0.9317, -0.9403,  0.1543,  0.0819,  0.1407,  0.7376,\n",
            "         -0.0664,  0.1264, -0.2334, -0.4810, -0.4672,  0.2994,  0.5686, -0.8317,\n",
            "         -0.8894, -0.9376, -0.0362, -0.2407,  0.1332, -0.1054,  0.6256,  0.1907,\n",
            "          0.7606, -0.8624, -0.9345,  0.1888, -0.4256,  0.9873, -0.0844, -0.9897,\n",
            "         -0.8414, -0.9409,  0.3353,  0.9394, -0.9155, -0.9632,  0.0732, -0.0712,\n",
            "         -0.9928,  0.2282,  0.0664,  0.0041, -0.9310,  0.2574,  0.7447, -0.0829,\n",
            "         -0.2282,  0.7383, -0.0220,  0.3624,  0.1620, -0.3558,  0.1313, -0.2259,\n",
            "          0.2066, -0.1824, -0.2640, -0.4579, -0.7711,  0.3879,  0.3003, -0.1999,\n",
            "          0.1231, -0.9582,  0.3688, -0.1023, -0.9800, -0.3029, -0.9925,  0.7494,\n",
            "          0.0137, -0.0634,  0.9382,  0.7872,  0.1795, -0.0457,  0.9553, -0.9863,\n",
            "          0.0772, -0.1486,  0.7654, -0.0833, -0.9879, -0.9745,  0.4331,  0.9315,\n",
            "          0.0902,  0.9431, -0.1878,  0.9479,  0.8131,  0.5565, -0.7737, -0.3848,\n",
            "         -0.0738,  0.1878, -0.7109,  0.0703,  0.0346, -0.2315,  0.1797, -0.1321,\n",
            "          0.8926, -0.9478, -0.4426,  0.9469,  0.7403,  0.9450,  0.9355, -0.0095,\n",
            "         -0.4273,  0.6991, -0.0027,  0.2044,  0.5770,  0.0306, -0.8324,  0.5327,\n",
            "         -0.7768,  0.4833,  0.1989, -0.0986,  0.9129, -0.9901, -0.0252,  0.3078,\n",
            "          0.9924,  0.7141,  0.2041, -0.7304, -0.0956,  0.0825, -0.9628,  0.9865,\n",
            "         -0.1949,  0.2626,  0.6666, -0.8059, -0.8608, -0.7182,  0.6236,  0.2977,\n",
            "         -0.9048, -0.0682, -0.4445, -0.2058,  0.3170,  0.6162, -0.0962, -0.3130,\n",
            "         -0.1450,  0.9385,  0.7920,  0.7902, -0.7374,  0.4368, -0.9060, -0.6638,\n",
            "          0.0793,  0.2596,  0.2070,  0.9945,  0.2795, -0.0533, -0.8581, -0.9848,\n",
            "          0.1053, -0.8736, -0.1578, -0.6325,  0.1105,  0.7095, -0.7802,  0.2606,\n",
            "         -0.9112, -0.6896,  0.1288, -0.1342,  0.0801, -0.0335,  0.8824, -0.9046,\n",
            "         -0.6232,  0.6550,  0.9481,  0.9138, -0.7359,  0.6457,  0.0506,  0.7618,\n",
            "         -0.4507,  0.9160, -0.5540,  0.3535, -0.9570,  0.8549, -0.6360,  0.8715,\n",
            "          0.0226, -0.9276, -0.9028,  0.2233,  0.1011,  0.9697, -0.5616,  0.9312,\n",
            "         -0.9412, -0.9754, -0.3282,  0.2797, -0.9916, -0.6582,  0.2071, -0.4366,\n",
            "         -0.1784, -0.1438, -0.9771,  0.8467,  0.2916,  0.8984,  0.3815, -0.8154,\n",
            "          0.3654, -0.9673,  0.2357,  0.0016,  0.9082, -0.0272, -0.9415,  0.2745,\n",
            "          0.7300,  0.1993,  0.9828,  0.9437,  0.3264,  0.9878,  0.8962,  0.6349,\n",
            "          0.4070,  0.0695,  0.9944,  0.5840, -0.9162, -0.9052, -0.1086,  0.4076,\n",
            "         -0.9800, -0.1689, -0.0024, -0.9402, -0.8537,  0.9810,  0.8391, -0.9695,\n",
            "          0.7206,  0.9446, -0.3811, -0.2304,  0.3327,  0.9847, -0.1247,  0.1269,\n",
            "          0.0148,  0.2205,  0.8646, -0.6211,  0.8345,  0.8522, -0.8143, -0.0559,\n",
            "         -0.4306, -0.9359, -0.1683, -0.1779, -0.5652, -0.9793, -0.2414, -0.5513,\n",
            "          0.4959,  0.0139,  0.1970, -0.7191, -0.0567, -0.8869,  0.0861,  0.2970,\n",
            "         -0.7921, -0.6133,  0.0755, -0.6813,  0.8312, -0.9755,  0.9755, -0.1069,\n",
            "         -0.8283,  0.9741,  0.0544, -0.8706, -0.1731,  0.0204, -0.0864,  0.9739,\n",
            "         -0.3524, -0.9906, -0.3787, -0.5822,  0.0290, -0.1294,  0.9830,  0.0117,\n",
            "          0.8360,  0.6440,  0.9900, -0.9955, -0.8500, -0.8939, -0.9838,  0.9607,\n",
            "          0.9669, -0.0940, -0.4069, -0.0148,  0.8055,  0.1019, -0.8218,  0.2145,\n",
            "          0.4026, -0.1220,  0.9148, -0.6922, -0.2382,  0.2129,  0.5824,  0.7011,\n",
            "         -0.8503,  0.1701, -0.3005,  0.0067, -0.1765, -0.7105, -0.9754, -0.3708,\n",
            "          0.9556,  0.4304, -0.3530,  0.7376,  0.0234, -0.3076,  0.0352,  0.1246,\n",
            "         -0.1717, -0.6895, -0.6851, -0.7410, -0.9941,  0.7669,  0.0881, -0.1646,\n",
            "          0.8633,  0.0501,  0.1946, -0.7529, -0.6674,  0.0325,  0.4469, -0.9504,\n",
            "          0.9843, -0.2296,  0.2019,  0.5733,  0.9368, -0.5414, -0.4062, -0.0135,\n",
            "         -0.9432, -0.1557, -0.9584,  0.9756, -0.9524,  0.1094,  0.2352, -0.5314,\n",
            "          0.9223, -0.6930,  0.6124, -0.0448,  0.8463,  0.7336, -0.6530, -0.2390,\n",
            "         -0.0830,  0.9056, -0.2493,  0.1430, -0.9765, -0.9296, -0.2766, -0.8913,\n",
            "         -0.9910,  0.7970,  0.2508,  0.3284,  0.0378, -0.1998, -0.5979, -0.1431,\n",
            "          0.0780, -0.9685,  0.9223, -0.2036,  0.3070, -0.1113,  0.2732, -0.9321,\n",
            "          0.9380,  0.8461,  0.3892, -0.0139, -0.6750,  0.7254, -0.7531,  0.8588,\n",
            "         -0.3040,  0.9832, -0.5088, -0.8229,  0.7534,  0.5943, -0.1395,  0.3696,\n",
            "         -0.8676,  0.3205,  0.9471,  0.9302, -0.5187, -0.2804,  0.4601, -0.7580,\n",
            "         -0.9178,  0.7972, -0.3823,  0.0720,  0.1094,  0.0668,  0.9402, -0.1857,\n",
            "          0.2691, -0.2700, -0.3343, -0.1468, -0.5852,  0.8820,  0.2889, -0.2252,\n",
            "         -0.9932,  0.6322, -0.8307, -0.0248,  0.9257, -0.6775,  0.2687,  0.0836,\n",
            "         -0.0258,  0.5148, -0.1993, -0.2986,  0.0234,  0.2813,  0.9889, -0.2668,\n",
            "         -0.9832, -0.5759,  0.0298, -0.9756, -0.6791, -0.1284, -0.1500, -0.1303,\n",
            "          0.2945,  0.5660, -0.0933, -0.9816, -0.1398, -0.0673,  0.9872,  0.2242,\n",
            "         -0.1856, -0.9139, -0.9239, -0.5324,  0.9003, -0.9472,  0.9889, -0.9702,\n",
            "          0.1715,  0.9609,  0.2963, -0.9172,  0.1264, -0.2513, -0.0236,  0.0614,\n",
            "          0.4245, -0.9385, -0.0983, -0.1315, -0.0214, -0.0334,  0.4844,  0.8136,\n",
            "          0.3620, -0.3498, -0.3401, -0.1191,  0.2880,  0.7063, -0.2574,  0.0087,\n",
            "          0.0304, -0.1110, -0.9471, -0.2235, -0.2266,  0.1150,  0.5775, -0.9802,\n",
            "         -0.7214, -0.9105, -0.3145,  0.8574,  0.0703, -0.7704, -0.7135,  0.9119,\n",
            "          0.9731,  0.6760, -0.3002,  0.6900, -0.8230,  0.0160, -0.0714,  0.1635,\n",
            "          0.5498,  0.6436, -0.0864,  0.9908,  0.0126, -0.3437, -0.9133,  0.2407,\n",
            "         -0.0929,  0.4734, -0.7425, -0.9688,  0.1588, -0.1395, -0.8918,  0.1415,\n",
            "         -0.0285, -0.4462,  0.4227,  0.9409,  0.6606, -0.0641,  0.3362, -0.2228,\n",
            "         -0.4332,  0.1941, -0.9175,  0.9905, -0.0430,  0.7810,  0.6010, -0.1413,\n",
            "          0.9713,  0.0926,  0.5926, -0.0403,  0.9399,  0.2154, -0.9089,  0.1603,\n",
            "         -0.9616, -0.1562, -0.9182,  0.2078,  0.0700,  0.8899, -0.2720,  0.9674,\n",
            "          0.9035,  0.2125,  0.4332,  0.8853,  0.2161, -0.9447, -0.9918, -0.9955,\n",
            "          0.0436, -0.4486, -0.0987,  0.4909, -0.0089,  0.2964,  0.1920, -0.8566,\n",
            "          0.9433,  0.3444, -0.9216,  0.9763, -0.1518, -0.1900,  0.1363, -0.9889,\n",
            "         -0.7786, -0.0455, -0.1186,  0.4095,  0.4904,  0.8873,  0.1354, -0.2589,\n",
            "         -0.1133,  0.7555, -0.5920, -0.9967,  0.3974,  0.9286, -0.8776,  0.9819,\n",
            "         -0.8789, -0.2460,  0.9303,  0.8343,  0.7512,  0.4939,  0.3818,  0.2316,\n",
            "          0.6652,  0.9110,  0.7296,  0.9945,  0.9201,  0.5459,  0.8281,  0.1533,\n",
            "          0.8450, -0.9512,  0.0969, -0.2906,  0.2981,  0.2794, -0.1428, -0.8213,\n",
            "          0.5334, -0.0248,  0.5155, -0.2505,  0.2441, -0.3792, -0.1712, -0.5809,\n",
            "         -0.4915,  0.2946,  0.2616,  0.9368, -0.0939, -0.1997, -0.2171, -0.0844,\n",
            "          0.9483, -0.9299,  0.6766, -0.1716,  0.9152, -0.6374, -0.1608,  0.7507,\n",
            "         -0.7564, -0.1182, -0.1311, -0.4814,  0.6681,  0.0760, -0.2009, -0.5860,\n",
            "          0.4497,  0.2718, -0.2162,  0.8563,  0.9027,  0.0927, -0.1250,  0.2605,\n",
            "         -0.1579, -0.9041,  0.2673,  0.8402, -0.7829,  0.4735, -0.9103,  0.7423,\n",
            "         -0.9188, -0.1376, -0.0970, -0.7197, -0.2525, -0.0017,  0.1718,  0.7139,\n",
            "         -0.6402,  0.8949,  0.4883,  0.9458,  0.3892,  0.8462, -0.5010,  0.8806]],\n",
            "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "# Load the model weights using hugingface model hub\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Example of getting the output of the model for a given text\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Use the model in inference mode and classify a give example\n",
        "def classify(text):\n",
        "    inputs = tokenize_text(text)\n",
        "    print(inputs)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs\n",
        "\n",
        "text = \"Hello World\"\n",
        "outputs = classify(text)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmqcGrIIAx7O"
      },
      "source": [
        "##### Import the multilabel data\n",
        "##### [UCBerkeley - Hate Speech Dataset (Multilabel)](https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "leJCUbz7Ax7O",
        "outputId": "c81f5f0d-43ff-41df-9013-fbaaa0aef07d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  sentiment  \\\n",
              "0       Yes indeed. She sort of reminds me of the elde...        0.0   \n",
              "1       The trans women reading this tweet right now i...        0.0   \n",
              "2       Question: These 4 broads who criticize America...        4.0   \n",
              "3       It is about time for all illegals to go back t...        2.0   \n",
              "4       For starters bend over the one in pink and kic...        4.0   \n",
              "...                                                   ...        ...   \n",
              "135551  عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...        1.0   \n",
              "135552  Millions of #Yemen-is participated in mass ral...        2.0   \n",
              "135553  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...        1.0   \n",
              "135554  Millions of #Yemen-is participated in mass ral...        2.0   \n",
              "135555  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...        4.0   \n",
              "\n",
              "        hatespeech  hate_speech_score  respect  insult  humiliate  status  \\\n",
              "0              0.0              -3.90      0.0     0.0        0.0     2.0   \n",
              "1              0.0              -6.52      0.0     0.0        0.0     2.0   \n",
              "2              2.0               0.36      4.0     4.0        4.0     4.0   \n",
              "3              0.0               0.26      3.0     2.0        1.0     2.0   \n",
              "4              2.0               1.54      4.0     4.0        4.0     4.0   \n",
              "...            ...                ...      ...     ...        ...     ...   \n",
              "135551         0.0              -4.88      1.0     0.0        0.0     2.0   \n",
              "135552         0.0              -4.40      0.0     0.0        0.0     2.0   \n",
              "135553         0.0              -2.49      1.0     1.0        1.0     1.0   \n",
              "135554         0.0              -4.40      0.0     0.0        0.0     2.0   \n",
              "135555         2.0              -0.20      4.0     4.0        2.0     2.0   \n",
              "\n",
              "        dehumanize  violence  genocide  attack_defend  \n",
              "0              0.0       0.0       0.0            0.0  \n",
              "1              0.0       0.0       0.0            2.0  \n",
              "2              4.0       0.0       0.0            4.0  \n",
              "3              0.0       0.0       0.0            3.0  \n",
              "4              4.0       4.0       1.0            3.0  \n",
              "...            ...       ...       ...            ...  \n",
              "135551         0.0       0.0       0.0            2.0  \n",
              "135552         0.0       0.0       0.0            1.0  \n",
              "135553         0.0       0.0       0.0            1.0  \n",
              "135554         0.0       0.0       0.0            2.0  \n",
              "135555         2.0       3.0       1.0            3.0  \n",
              "\n",
              "[135556 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dd651f8-37a5-4f53-a2b3-bfbbcf992910\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>hatespeech</th>\n",
              "      <th>hate_speech_score</th>\n",
              "      <th>respect</th>\n",
              "      <th>insult</th>\n",
              "      <th>humiliate</th>\n",
              "      <th>status</th>\n",
              "      <th>dehumanize</th>\n",
              "      <th>violence</th>\n",
              "      <th>genocide</th>\n",
              "      <th>attack_defend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The trans women reading this tweet right now i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: These 4 broads who criticize America...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It is about time for all illegals to go back t...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For starters bend over the one in pink and kic...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135551</th>\n",
              "      <td>عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.88</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135552</th>\n",
              "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135553</th>\n",
              "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135554</th>\n",
              "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135555</th>\n",
              "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135556 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dd651f8-37a5-4f53-a2b3-bfbbcf992910')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dd651f8-37a5-4f53-a2b3-bfbbcf992910 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dd651f8-37a5-4f53-a2b3-bfbbcf992910');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91bbc372-e6bb-4030-9497-557de129d9c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91bbc372-e6bb-4030-9497-557de129d9c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91bbc372-e6bb-4030-9497-557de129d9c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multilabel_dataset"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Download the data locally\n",
        "# https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech/tree/main\n",
        "\n",
        "## Read the measuring-hate-speech.parquet\n",
        "parquet_data = pd.read_parquet('measuring-hate-speech.parquet')\n",
        "\n",
        "## remove from df the redundant  columns\n",
        "multilabel_dataset = parquet_data.iloc[:, :-116]\n",
        "\n",
        "## Remove comment_idm,annotator_id,platform and put the column text in the first position\n",
        "multilabel_dataset = multilabel_dataset[['text','sentiment', 'hatespeech', 'hate_speech_score', 'respect','insult','humiliate','status','dehumanize','violence','genocide' ,'attack_defend']]\n",
        "multilabel_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_FEkRzAx7O"
      },
      "source": [
        "### Preprocessing text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "An20B7vYAx7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed7c8e3-d6a6-4f59-df29-a4e13fc3734b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "## Preprocess the TEXT data\n",
        "## Remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: remove_html_tags(x))\n",
        "\n",
        "## Remove URL\n",
        "def remove_url(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "## Lowercase\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].str.lower()\n",
        "\n",
        "## Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "## Handling Contractions using libraries\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "## Remove stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "## Lemmatization\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "multilabel_dataset['text'] = multilabel_dataset['text'].apply(lambda x: lemmatize_words(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy2Nc1NKAx7O"
      },
      "source": [
        "#### Preprocess labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DekxvQztAx7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "45453afa-ee4c-4940-fb54-a9da5a31b2ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  sentiment  \\\n",
              "0       yes indeed sort reminds elder lady played part...        0.0   \n",
              "1               trans woman reading tweet right beautiful        0.0   \n",
              "2       question 4 broad criticize america country fle...        4.0   \n",
              "3       time illegals go back country origin keep free...        2.0   \n",
              "4       starter bend one pink kick as pussy get taste ...        4.0   \n",
              "...                                                   ...        ...   \n",
              "135551  عاجل سماحة السيد_عبدالملك_بدرالدين_الحوثي نصره...        1.0   \n",
              "135552  million yemeni participated mass rally 13squar...        2.0   \n",
              "135553  abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...        1.0   \n",
              "135554  million yemeni participated mass rally 13squar...        2.0   \n",
              "135555  لا تتشمت الرجال مسكين يعاني كس امه يقول ياليته...        4.0   \n",
              "\n",
              "        hatespeech  hate_speech_score  respect  insult  humiliate  status  \\\n",
              "0              0.0              -3.90        0       0          0       1   \n",
              "1              0.0              -6.52        0       0          0       1   \n",
              "2              2.0               0.36        1       1          1       1   \n",
              "3              0.0               0.26        1       1          1       1   \n",
              "4              2.0               1.54        1       1          1       1   \n",
              "...            ...                ...      ...     ...        ...     ...   \n",
              "135551         0.0              -4.88        1       0          0       1   \n",
              "135552         0.0              -4.40        0       0          0       1   \n",
              "135553         0.0              -2.49        1       1          1       1   \n",
              "135554         0.0              -4.40        0       0          0       1   \n",
              "135555         2.0              -0.20        1       1          1       1   \n",
              "\n",
              "        dehumanize  violence  genocide  attack_defend  \n",
              "0                0         0         0              0  \n",
              "1                0         0         0              1  \n",
              "2                1         0         0              1  \n",
              "3                0         0         0              1  \n",
              "4                1         1         1              1  \n",
              "...            ...       ...       ...            ...  \n",
              "135551           0         0         0              1  \n",
              "135552           0         0         0              1  \n",
              "135553           0         0         0              1  \n",
              "135554           0         0         0              1  \n",
              "135555           1         1         1              1  \n",
              "\n",
              "[135556 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f29408ba-860b-4ab4-a56d-e6a4dddef519\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>hatespeech</th>\n",
              "      <th>hate_speech_score</th>\n",
              "      <th>respect</th>\n",
              "      <th>insult</th>\n",
              "      <th>humiliate</th>\n",
              "      <th>status</th>\n",
              "      <th>dehumanize</th>\n",
              "      <th>violence</th>\n",
              "      <th>genocide</th>\n",
              "      <th>attack_defend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes indeed sort reminds elder lady played part...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trans woman reading tweet right beautiful</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question 4 broad criticize america country fle...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>time illegals go back country origin keep free...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>starter bend one pink kick as pussy get taste ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135551</th>\n",
              "      <td>عاجل سماحة السيد_عبدالملك_بدرالدين_الحوثي نصره...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135552</th>\n",
              "      <td>million yemeni participated mass rally 13squar...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135553</th>\n",
              "      <td>abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.49</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135554</th>\n",
              "      <td>million yemeni participated mass rally 13squar...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135555</th>\n",
              "      <td>لا تتشمت الرجال مسكين يعاني كس امه يقول ياليته...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135556 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f29408ba-860b-4ab4-a56d-e6a4dddef519')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f29408ba-860b-4ab4-a56d-e6a4dddef519 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f29408ba-860b-4ab4-a56d-e6a4dddef519');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62529eff-6cbb-47e9-b819-0b7c86859062\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62529eff-6cbb-47e9-b819-0b7c86859062')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62529eff-6cbb-47e9-b819-0b7c86859062 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multilabel_dataset"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## Replace each catefory of hatespeech with 0 or 1 for the columns respect, insult, humiliate, status, dehumanize, violence, genocide, attack_defend\n",
        "## Do it more efficiently\n",
        "\n",
        "# List of columns to transform\n",
        "columns_to_transform = ['respect', 'insult', 'humiliate', 'status',\n",
        "                        'dehumanize', 'violence', 'genocide', 'attack_defend']\n",
        "\n",
        "# Apply the transformation\n",
        "for column in columns_to_transform:\n",
        "    multilabel_dataset[column] = multilabel_dataset[column].apply(lambda x: 1 if x > 0 else 0)\n",
        "multilabel_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel_dataset['labels']=multilabel_dataset[columns_to_transform].values.tolist()\n",
        "multilabel_dataset = multilabel_dataset[multilabel_dataset['text'] != '']\n",
        "multilabel_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "mrzMT17xlNW6",
        "outputId": "823cd19d-b572-46d2-c8a3-4c70a2c426fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  sentiment  \\\n",
              "0       yes indeed sort reminds elder lady played part...        0.0   \n",
              "1               trans woman reading tweet right beautiful        0.0   \n",
              "2       question 4 broad criticize america country fle...        4.0   \n",
              "3       time illegals go back country origin keep free...        2.0   \n",
              "4       starter bend one pink kick as pussy get taste ...        4.0   \n",
              "...                                                   ...        ...   \n",
              "135551  عاجل سماحة السيد_عبدالملك_بدرالدين_الحوثي نصره...        1.0   \n",
              "135552  million yemeni participated mass rally 13squar...        2.0   \n",
              "135553  abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...        1.0   \n",
              "135554  million yemeni participated mass rally 13squar...        2.0   \n",
              "135555  لا تتشمت الرجال مسكين يعاني كس امه يقول ياليته...        4.0   \n",
              "\n",
              "        hatespeech  hate_speech_score  respect  insult  humiliate  status  \\\n",
              "0              0.0              -3.90        0       0          0       1   \n",
              "1              0.0              -6.52        0       0          0       1   \n",
              "2              2.0               0.36        1       1          1       1   \n",
              "3              0.0               0.26        1       1          1       1   \n",
              "4              2.0               1.54        1       1          1       1   \n",
              "...            ...                ...      ...     ...        ...     ...   \n",
              "135551         0.0              -4.88        1       0          0       1   \n",
              "135552         0.0              -4.40        0       0          0       1   \n",
              "135553         0.0              -2.49        1       1          1       1   \n",
              "135554         0.0              -4.40        0       0          0       1   \n",
              "135555         2.0              -0.20        1       1          1       1   \n",
              "\n",
              "        dehumanize  violence  genocide  attack_defend  \\\n",
              "0                0         0         0              0   \n",
              "1                0         0         0              1   \n",
              "2                1         0         0              1   \n",
              "3                0         0         0              1   \n",
              "4                1         1         1              1   \n",
              "...            ...       ...       ...            ...   \n",
              "135551           0         0         0              1   \n",
              "135552           0         0         0              1   \n",
              "135553           0         0         0              1   \n",
              "135554           0         0         0              1   \n",
              "135555           1         1         1              1   \n",
              "\n",
              "                          labels  \n",
              "0       [0, 0, 0, 1, 0, 0, 0, 0]  \n",
              "1       [0, 0, 0, 1, 0, 0, 0, 1]  \n",
              "2       [1, 1, 1, 1, 1, 0, 0, 1]  \n",
              "3       [1, 1, 1, 1, 0, 0, 0, 1]  \n",
              "4       [1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "...                          ...  \n",
              "135551  [1, 0, 0, 1, 0, 0, 0, 1]  \n",
              "135552  [0, 0, 0, 1, 0, 0, 0, 1]  \n",
              "135553  [1, 1, 1, 1, 0, 0, 0, 1]  \n",
              "135554  [0, 0, 0, 1, 0, 0, 0, 1]  \n",
              "135555  [1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "\n",
              "[135555 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b58eb77b-a9b4-47b8-a55d-e8d1c97c484f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>hatespeech</th>\n",
              "      <th>hate_speech_score</th>\n",
              "      <th>respect</th>\n",
              "      <th>insult</th>\n",
              "      <th>humiliate</th>\n",
              "      <th>status</th>\n",
              "      <th>dehumanize</th>\n",
              "      <th>violence</th>\n",
              "      <th>genocide</th>\n",
              "      <th>attack_defend</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes indeed sort reminds elder lady played part...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trans woman reading tweet right beautiful</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question 4 broad criticize america country fle...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 1, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>time illegals go back country origin keep free...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>starter bend one pink kick as pussy get taste ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135551</th>\n",
              "      <td>عاجل سماحة السيد_عبدالملك_بدرالدين_الحوثي نصره...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135552</th>\n",
              "      <td>million yemeni participated mass rally 13squar...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135553</th>\n",
              "      <td>abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.49</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135554</th>\n",
              "      <td>million yemeni participated mass rally 13squar...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135555</th>\n",
              "      <td>لا تتشمت الرجال مسكين يعاني كس امه يقول ياليته...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135555 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b58eb77b-a9b4-47b8-a55d-e8d1c97c484f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b58eb77b-a9b4-47b8-a55d-e8d1c97c484f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b58eb77b-a9b4-47b8-a55d-e8d1c97c484f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0a9ea6a-4fea-4dd4-b74b-309ec2e63a88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a9ea6a-4fea-4dd4-b74b-309ec2e63a88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0a9ea6a-4fea-4dd4-b74b-309ec2e63a88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multilabel_dataset"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fFnGp-_Ax7P"
      },
      "source": [
        "#### Dataset/Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V3jk6gaBAx7P"
      },
      "outputs": [],
      "source": [
        "#X = multilabel_dataset['text'].values.tolist()\n",
        "#encoded_inputs = tokenizer(X, padding=True, truncation=True,max_length=256, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = multilabel_dataset[columns_to_transform].values  # Assuming you have extracted binary labels\n",
        "#encoded_inputs['labels']=torch.tensor(labels, dtype=torch.float)"
      ],
      "metadata": {
        "id": "D28WbbSePswY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoded_inputs"
      ],
      "metadata": {
        "id": "QiSy4JfgPxZG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = multilabel_dataset['text'].values\n",
        "#labels = multilabel_dataset[columns_to_transform].values"
      ],
      "metadata": {
        "id": "cF6riV55RcVu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05"
      ],
      "metadata": {
        "id": "9Fik-IuMl2Gd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "2tNG2TgMST05"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HateSpeechDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer,max_len=256):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.text = data.text\n",
        "        self.targets = self.data.labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        text = str(self.text.iloc[idx])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "\n",
        "        ids = encoding['input_ids']\n",
        "        mask = encoding['attention_mask']\n",
        "        token_type_ids = encoding['token_type_ids']\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets.iloc[idx], dtype=torch.float).to(device)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "8dNmnpeaRNEJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts,= train_test_split(multilabel_dataset,test_size=0.2)\n",
        "\n",
        "print(\"Dataset length: {}\".format(multilabel_dataset.shape))\n",
        "print(\"Train Dataset length: {}\".format(train_texts.shape))\n",
        "print(\"Val Dataset length: {}\".format(val_texts.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P2OPdrMpr5A",
        "outputId": "ab1af6a0-e5da-45ea-af5e-f06ab53db1f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: (135555, 13)\n",
            "Train Dataset length: (108444, 13)\n",
            "Val Dataset length: (27111, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = HateSpeechDataset(train_texts,tokenizer,MAX_LEN)\n",
        "validation_dataset = HateSpeechDataset(val_texts,tokenizer,MAX_LEN)"
      ],
      "metadata": {
        "id": "zsZE_CsgqKwR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_dataset, **train_params)\n",
        "validation_loader = DataLoader(validation_dataset, **test_params)"
      ],
      "metadata": {
        "id": "DQ_NhbqZRiJw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(training_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vjtlh6IuMvu",
        "outputId": "783876a0-fc5b-4a79-d96e-e54824d123e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  7564,  3350,  ...,     0,     0,     0],\n",
              "         [  101,  2729,  5561,  ...,     0,     0,     0],\n",
              "         [  101, 20342,  2004,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  2052, 24357,  ...,     0,     0,     0],\n",
              "         [  101,  2304,  2796,  ...,     0,     0,     0],\n",
              "         [  101,  4297,  9050,  ...,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
              " 'targets': tensor([[1., 0., 0., 1., 1., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 0., 0., 1.],\n",
              "         [1., 0., 0., 1., 0., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 0., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 0., 0., 1., 0., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 0., 1.],\n",
              "         [1., 0., 0., 1., 0., 0., 0., 1.],\n",
              "         [1., 1., 1., 1., 1., 0., 0., 1.]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine Tuning the model"
      ],
      "metadata": {
        "id": "2ZnNREnNqdmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji2lKZOtbwVg",
        "outputId": "6f30ef47-9741-4f56-901c-1abaf637ebb4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "\n",
        "class MultilabelHateBert(torch.nn.Module):\n",
        "    def __init__(self,bertmodel):\n",
        "        super(MultilabelHateBert, self).__init__()\n",
        "        self.bertmodel = bertmodel\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, len(columns_to_transform))\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "\n",
        "      output_1= self.bertmodel(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      output_2 = self.dropout(output_1.pooler_output)\n",
        "      output = self.linear(output_2)\n",
        "      return output\n",
        "\n",
        "multilabel_model = MultilabelHateBert(model)\n",
        "multilabel_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2vjORRaqfMf",
        "outputId": "80552444-dba1-4aa2-8bb4-bda3f81e90c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilabelHateBert(\n",
              "  (bertmodel): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "metadata": {
        "id": "C4t_4UYLrLzl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params =  multilabel_model.parameters(), lr=LEARNING_RATE)\n"
      ],
      "metadata": {
        "id": "RP5gXTDerK8F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Loop"
      ],
      "metadata": {
        "id": "GvLOZaOYq0mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "\n",
        "  multilabel_model.train()\n",
        "\n",
        "  for i, batch in tqdm(enumerate(training_loader), desc=f\"Epoch {epoch + 1}\", total=len(training_loader)):\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    targets = batch['targets'].to(device)\n",
        "\n",
        "    outputs = multilabel_model(input_ids,attention_mask,token_type_ids)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs,targets)\n",
        "\n",
        "    if i%50==0:\n",
        "      print()\n",
        "      print(f'Epoch: {epoch}, Loss{loss.item()}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO3pp7Xq3cj",
        "outputId": "dd0cf7c3-e176-4705-ef77-4b74b49effed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/6778 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0, Loss0.6766090393066406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 1:   0%|          | 1/6778 [00:00<1:43:42,  1.09it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 2/6778 [00:01<50:59,  2.21it/s]  \u001b[A\n",
            "Epoch 1:   0%|          | 3/6778 [00:01<1:00:31,  1.87it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 4/6778 [00:02<1:05:52,  1.71it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 5/6778 [00:02<1:07:52,  1.66it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 6/6778 [00:03<1:10:19,  1.61it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 7/6778 [00:04<1:13:42,  1.53it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 8/6778 [00:04<1:12:30,  1.56it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 9/6778 [00:05<1:16:27,  1.48it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 10/6778 [00:06<1:11:29,  1.58it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 11/6778 [00:07<1:17:51,  1.45it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 12/6778 [00:07<1:16:30,  1.47it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 13/6778 [00:08<1:14:43,  1.51it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 14/6778 [00:08<1:12:02,  1.56it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 15/6778 [00:09<1:15:08,  1.50it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 16/6778 [00:10<1:12:41,  1.55it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 17/6778 [00:11<1:16:45,  1.47it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 18/6778 [00:11<1:17:51,  1.45it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 19/6778 [00:12<1:15:04,  1.50it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 20/6778 [00:13<1:14:30,  1.51it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 21/6778 [00:13<1:15:18,  1.50it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation Loop"
      ],
      "metadata": {
        "id": "UVFsvSa8sCg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "\n",
        "  multilabel_model.eval()\n",
        "  val_targets=[]\n",
        "  val_outputs=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for i,batch in enumerate(validation_loader):\n",
        "\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      token_type_ids = batch['token_type_ids'].to(device)\n",
        "      targets = batch['targets'].to(device)\n",
        "\n",
        "      outputs = multilabel_model(input_ids,attention_mask,token_type_ids)\n",
        "\n",
        "      val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "  outputs = np.array(val_outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(val_targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(val_targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(val_targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "7wnDBL3Sr_Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel_model"
      ],
      "metadata": {
        "id": "GLotaC7Hc-GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(multilabel_model.state_dict(), '/content/drive/fine_tuning_v1.2')"
      ],
      "metadata": {
        "id": "pMa5YZlOg9VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#multilabel_model1 = MultilabelHateBert(model)\n",
        "#multilabel_model1.load_state_dict(torch.load('/content/fine_tuning_v1.1'))"
      ],
      "metadata": {
        "id": "qZd3WuYYhWu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretability"
      ],
      "metadata": {
        "id": "uU6oSqi4e1SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel_dataset"
      ],
      "metadata": {
        "id": "UcyceZEB4QKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import\n",
        "! pip install lime\n",
        "! pip install transformers-interpret"
      ],
      "metadata": {
        "id": "wMa-pFT4eLAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [17, 4, 44, 3, 8, 27, 71, 74]\n",
        "attributions = dict()\n",
        "attributions['LIME'] = []"
      ],
      "metadata": {
        "id": "HwGhn9reeNZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=columns_to_transform, split_expression='\\s+', bow=False)"
      ],
      "metadata": {
        "id": "XLziYQw3eWuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predictor(texts):\n",
        "\n",
        "    encodings = tokenizer(texts,\n",
        "                           padding='max_length',\n",
        "                           truncation=True,\n",
        "                           max_length=MAX_LEN,\n",
        "                           return_tensors='pt')\n",
        "\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "    token_type_ids = encodings['token_type_ids'].to(device)\n",
        "\n",
        "    logits = multilabel_model(input_ids, attention_mask, token_type_ids)\n",
        "    probabilities = F.softmax(logits, dim=1)\n",
        "\n",
        "    return probabilities.cpu().detach().numpy()\n",
        "\n",
        "for idx in samples:\n",
        "    instance = val_texts.iloc[idx].text\n",
        "\n",
        "    # Call predictor with the current instance\n",
        "    exp = explainer.explain_instance(instance, predictor, num_features=200, num_samples=64)\n",
        "\n",
        "    explanation_dict = dict(list(exp.as_map().values())[0])\n",
        "    tokens = val_texts.iloc[idx].text.split(' ')\n",
        "    scores = []\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "        scores.append((tokens[i], explanation_dict[i]))\n",
        "\n",
        "    attributions['LIME'].append(scores)"
      ],
      "metadata": {
        "id": "ePv2Rh1F6V1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm, transforms\n",
        "\n",
        "# Plotting Code from innvestigate library: https://github.com/albermax/innvestigate\n",
        "def plot_text_heatmap(words, scores, title=\"\", width=10, height=0.2, verbose=0, max_word_per_line=20):\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    ax.set_title(title, loc='left')\n",
        "    tokens = words\n",
        "    if verbose > 0:\n",
        "        print('len words : %d | len scores : %d' % (len(words), len(scores)))\n",
        "\n",
        "    cmap = plt.cm.ScalarMappable(cmap=cm.bwr)\n",
        "    cmap.set_clim(0, 1)\n",
        "\n",
        "    canvas = ax.figure.canvas\n",
        "    t = ax.transData\n",
        "\n",
        "    # normalize scores to the followings:\n",
        "    # - negative scores in [0, 0.5]\n",
        "    # - positive scores in (0.5, 1]\n",
        "    normalized_scores = 0.5 * scores / np.max(np.abs(scores)) + 0.5\n",
        "\n",
        "    if verbose > 1:\n",
        "        print('Raw score')\n",
        "        print(scores)\n",
        "        print('Normalized score')\n",
        "        print(normalized_scores)\n",
        "\n",
        "    # make sure the heatmap doesn't overlap with the title\n",
        "    loc_y = -0.2\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        *rgb, _ = cmap.to_rgba(normalized_scores[i], bytes=True)\n",
        "        color = '#%02x%02x%02x' % tuple(rgb)\n",
        "\n",
        "        text = ax.text(0.0, loc_y, token,\n",
        "                       bbox={\n",
        "                           'facecolor': color,\n",
        "                           'pad': 5.0,\n",
        "                           'linewidth': 1,\n",
        "                           'boxstyle': 'round,pad=0.5'\n",
        "                       }, transform=t)\n",
        "\n",
        "        text.draw(canvas.get_renderer())\n",
        "        ex = text.get_window_extent()\n",
        "\n",
        "        # create a new line if the line exceeds the length\n",
        "        if (i+1) % max_word_per_line == 0:\n",
        "            loc_y = loc_y -  2.5\n",
        "            t = ax.transData\n",
        "        else:\n",
        "            t = transforms.offset_copy(text._transform, x=ex.width+15, units='dots')\n",
        "\n",
        "    if verbose == 0:\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "yjtOrEylewau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "methods = ['LIME']\n",
        "\n",
        "for sample_id in range(len(samples)):\n",
        "    for method in methods:\n",
        "        analysis = attributions[method][sample_id]\n",
        "        words = [t[0] for t in analysis]\n",
        "        scores = np.array([t[1] for t in analysis])\n",
        "        plot_text_heatmap(words, scores, title='Method: %s' % method, verbose=0)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EVJMgkbFezl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}